<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>projected_lmc module &#8212; projected-lmc 0.0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b76e3c8a" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css?v=514cf933" />
    
    <script src="_static/documentation_options.js?v=d45e8c67"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">projected-lmc 0.0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">projected_lmc module</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="module-projected_lmc">
<span id="projected-lmc-module"></span><h1>projected_lmc module<a class="headerlink" href="#module-projected_lmc" title="Link to this heading">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.CustomLMCVariationalStrategy">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">CustomLMCVariationalStrategy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.CustomLMCVariationalStrategy" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">LMCVariationalStrategy</span></code></p>
<p>This small overlay to the native LMCVariationalStrategy of gpytorch allows to put deterministic means on tasks rather than latent processes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mean_module</strong> (<em>&lt;module 'gpytorch.means.mean' from '/home/catB/ot266455/anaconda3/envs/gp/lib/python3.10/site-packages/gpytorch/means/mean.py'&gt;</em>) – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.CustomLMCVariationalStrategy.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mean_module</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.CustomLMCVariationalStrategy.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>mean_module</strong> (<em>&lt;module 'gpytorch.means.mean' from '/home/catB/ot266455/anaconda3/envs/gp/lib/python3.10/site-packages/gpytorch/means/mean.py'&gt;</em>) – The already-generated, batched, many-tasks mean function to impose on output tasks.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.ExactGPModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">ExactGPModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_scales=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_width=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_type=&lt;class</span> <span class="pre">'gpytorch.means.constant_mean.ConstantMean'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomp=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputscales=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'gpytorch.kernels.rbf_kernel.RBFKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ker_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ExactGPModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGP</span></code></p>
<p>Standard exact GP model. Can handle independant multitasking via batch dimensions</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>train_y</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em>) – </p></li>
<li><p><strong>n_tasks</strong> (<em>int</em>) – </p></li>
<li><p><strong>prior_scales</strong> (<em>Tensor</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>prior_width</strong> (<em>Tensor</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>mean_type</strong> (<em>Mean</em>) – </p></li>
<li><p><strong>decomp</strong> (<em>list</em><em>[</em><em>list</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – </p></li>
<li><p><strong>outputscales</strong> (<em>bool</em>) – </p></li>
<li><p><strong>kernel_type</strong> (<em>Kernel</em>) – </p></li>
<li><p><strong>ker_kwargs</strong> (<em>dict</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ExactGPModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks=1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_scales=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_width=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_type=&lt;class</span> <span class="pre">'gpytorch.means.constant_mean.ConstantMean'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomp=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputscales=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'gpytorch.kernels.rbf_kernel.RBFKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ker_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ExactGPModel.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – training input data</p></li>
<li><p><strong>train_y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – training data labels</p></li>
<li><p><strong>n_latents</strong> – number of latent processes</p></li>
<li><p><strong>n_tasks</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of output tasks</p></li>
<li><p><strong>prior_scales</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Prior mean for characteristic lengthscales of the kernel. Defaults to None.</p></li>
<li><p><strong>prior_width</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Prior deviation-to-mean ratio for characteristic lengthscales of the kernel. Defaults to None.</p></li>
<li><p><strong>mean_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Mean</span></code>) – gpytorch mean function for the outputs. Defaults to gpytorch.means.ConstantMean.</p></li>
<li><p><strong>kernel_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code>) – . gpytorch kernel function for latent processes. Defaults to gpytorch.kernels.RBFKernel.</p></li>
<li><p><strong>decomp</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – instructions to create a composite kernel with subgroups of variables. Ex : decomp = [[0,1],[1,2]] –&gt; k(x0,x1,x2) = k1(x0,x1) + k2(x1,x2). Defaults to None.</p></li>
<li><p><strong>outputscales</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether to endow the kernel with a learned scaling factor, k(.) = a*k_base(.). Defaults to True</p></li>
<li><p><strong>ker_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>]) – Additional arguments to pass to the gpytorch kernel function. Defaults to None.</p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ExactGPModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ExactGPModel.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.
:type x: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param x: Data to evaluate the model at</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormal</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">MultitaskMultivariateNormal</span></code>]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Prior distribution of the model output at the input locations. Can be a multitask multivariate normal if batch dimension is &gt;1, or a multivariate normal otherwise</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ExactGPModel.lscales">
<span class="sig-name descname"><span class="pre">lscales</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unpacked</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ExactGPModel.lscales" title="Link to this definition">¶</a></dt>
<dd><p>Displays the learned characteric lengthscales of the kernel(s).
:type unpacked: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param unpacked: whether to unpack the output list and trim useless dimensions of the tensor.
:param Applies only if the model kernel is not composite. Defaults to True:</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of tensors representing the learned characteristic lengthscales of each subkernel and each task (or a single tensor if the kernel is non-composite and unpacked=True).
Each one has shape n_tasks x n_dims (n_dim number of dimensions of the subkernel)</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>unpacked</strong> (<em>bool</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ExactGPModel.outputscale">
<span class="sig-name descname"><span class="pre">outputscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unpacked</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ExactGPModel.outputscale" title="Link to this definition">¶</a></dt>
<dd><p>Displays the outputscale(s) of the kernel(s).
:type unpacked: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param unpacked: whether to trim useless dimensions of the tensor. Defaults to False</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensors representing the learned outputscales of each subkernel and each task (shape n_tasks x n_kernels)</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>unpacked</strong> (<em>bool</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.LMCMixingMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">LMCMixingMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_plus</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.LMCMixingMatrix" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Class for the parametrized mixing matrix of projected models. Making it a separate class allows to call
torch.nn.utils.parametrizations.orthogonal onto it during instanciation of a ProjectedGPModel</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Q_plus</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>R</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>n_latents</strong> (<em>int</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.LMCMixingMatrix.Q">
<span class="sig-name descname"><span class="pre">Q</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.LMCMixingMatrix.Q" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.LMCMixingMatrix.Q_orth">
<span class="sig-name descname"><span class="pre">Q_orth</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.LMCMixingMatrix.Q_orth" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.LMCMixingMatrix.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">Q_plus</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">R</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.LMCMixingMatrix.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Q_plus</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – (augmented) orthonormal part of the mixing matrix. See the reference article for explanations</p></li>
<li><p><strong>R</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – upper triangular part of the mixing matrix. See the reference article for explanations</p></li>
<li><p><strong>n_latents</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of latent processes</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.LMCMixingMatrix.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.LMCMixingMatrix.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.LMCMixingMatrix.size">
<span class="sig-name descname"><span class="pre">size</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">int</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.LMCMixingMatrix.size" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.MultitaskGPModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">MultitaskGPModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'IMC'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_lmc_coeffs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fix_diagonal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.MultitaskGPModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#projected_lmc.ExactGPModel" title="projected_lmc.ExactGPModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGPModel</span></code></a></p>
<p>A multitask GP model with exact GP treatment. This class encompasses both IMC and naive LMC models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>train_y</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>likelihood</strong> (<em>Likelihood</em>) – </p></li>
<li><p><strong>n_tasks</strong> (<em>int</em>) – </p></li>
<li><p><strong>n_latents</strong> (<em>int</em>) – </p></li>
<li><p><strong>model_type</strong> (<em>str</em>) – </p></li>
<li><p><strong>init_lmc_coeffs</strong> (<em>bool</em>) – </p></li>
<li><p><strong>fix_diagonal</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.MultitaskGPModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'IMC'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_lmc_coeffs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fix_diagonal</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.MultitaskGPModel.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialization of the model. Note that the optional arguments of the ExactGPModel also apply here thanks to the inheritance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Input data</p></li>
<li><p><strong>train_y</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – Input labels</p></li>
<li><p><strong>likelihood</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>) – Likelihood of the model</p></li>
<li><p><strong>n_tasks</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of tasks</p></li>
<li><p><strong>n_latents</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of latent functions</p></li>
<li><p><strong>model_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>) – choice between ‘IMC’ and ‘LMC’ (see the reference paper). Defaults to “IMC”</p></li>
<li><p><strong>init_lmc_coeffs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – if True, initializes LMC coefficients with SVD of the training labels ; else inializes with samples from standard normal distributions. Defaults to True</p></li>
<li><p><strong>fix_diagonal</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – for IMC only. If True, fixes the learned diagonal term of the task covariance matrix, accounting for task-specific (non-shared) latent processes. Defaults to False</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.MultitaskGPModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.MultitaskGPModel.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.
:type x: 
:param x: Data to evaluate the model at</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Prior distribution of the model output at the input locations. Can be a multitask multivariate normal if batch dimension is &gt;1, or a multivariate normal otherwise</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.MultitaskGPModel.lmc_coefficients">
<span class="sig-name descname"><span class="pre">lmc_coefficients</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.MultitaskGPModel.lmc_coefficients" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>tensor of shape n_latents x n_tasks representing the LMC/IMC coefficients of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.MultitaskGPModel.lscales">
<span class="sig-name descname"><span class="pre">lscales</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unpacked</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.MultitaskGPModel.lscales" title="Link to this definition">¶</a></dt>
<dd><p>Displays the learned characteric lengthscales of the kernel(s).
:type unpacked: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param unpacked: whether to unpack the output list and trim useless dimensions of the tensor.
:param Applies only if the model kernel is not composite. Defaults to True:</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of tensors representing the learned characteristic lengthscales of each subkernel and each task (or a single tensor if the kernel is non-composite and unpacked=True).
Each one has shape n_latents x n_dims (n_dim number of dimensions of the subkernel)</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>unpacked</strong> (<em>bool</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.MultitaskGPModel.outputscale">
<span class="sig-name descname"><span class="pre">outputscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unpacked</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.MultitaskGPModel.outputscale" title="Link to this definition">¶</a></dt>
<dd><p>Displays the outputscale(s) of the kernel(s).
:type unpacked: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param unpacked: whether to trim useless dimensions of the tensor. Defaults to False</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor representing the learned outputscales of each subkernel and each task (shape n_latents x n_kernels)</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>unpacked</strong> (<em>bool</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.PolynomialMean">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">PolynomialMean</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.PolynomialMean" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Mean</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<em>int</em>) – </p></li>
<li><p><strong>degree</strong> (<em>int</em>) – </p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em>) – </p></li>
<li><p><strong>bias</strong> (<em>bool</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.PolynomialMean.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">degree</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">bias</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.PolynomialMean.__init__" title="Link to this definition">¶</a></dt>
<dd><p>A mean function made of an order-d (univariate) polynomial in each variable</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – dimension of the data (number of variables)</p></li>
<li><p><strong>degree</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – degree of the polynomial, defaults to 3</p></li>
<li><p><strong>tasks</strong> (<em>bat in case</em><em> of </em><em>several batched</em>) – </p></li>
<li><p><strong>bias</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether or not to include a bias term, defaults to True</p></li>
<li><p><strong>batch_shape</strong> (<em>Size</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.PolynomialMean.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.PolynomialMean.forward" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – input data to be evaluated at</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A tensor of the values of the mean function at evaluation points.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.PositiveDiagonalParam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">PositiveDiagonalParam</span></span><a class="headerlink" href="#projected_lmc.PositiveDiagonalParam" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Torch parametrization for a positive diagonal matrix.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.PositiveDiagonalParam.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.PositiveDiagonalParam.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.PositiveDiagonalParam.right_inverse">
<span class="sig-name descname"><span class="pre">right_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.PositiveDiagonalParam.right_inverse" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>A</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.PositiveTriangularParam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">PositiveTriangularParam</span></span><a class="headerlink" href="#projected_lmc.PositiveTriangularParam" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Torch parametrization for a Cholesky factor matrix (lower triangular with positive diagonal).</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.PositiveTriangularParam.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.PositiveTriangularParam.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">ProjectedGPModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_lmc_coeffs=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">BDN=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diagonal_B=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar_B=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diagonal_R=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_type=&lt;class</span> <span class="pre">'gpytorch.means.constant_mean.ConstantMean'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#projected_lmc.ExactGPModel" title="projected_lmc.ExactGPModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ExactGPModel</span></code></a></p>
<p>The projected LMC from the reference article.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>train_y</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>n_tasks</strong> (<em>int</em>) – </p></li>
<li><p><strong>n_latents</strong> (<em>int</em>) – </p></li>
<li><p><strong>proj_likelihood</strong> (<em>None</em><em> | </em><em>Likelihood</em>) – </p></li>
<li><p><strong>init_lmc_coeffs</strong> (<em>bool</em>) – </p></li>
<li><p><strong>BDN</strong> (<em>bool</em>) – </p></li>
<li><p><strong>diagonal_B</strong> (<em>bool</em>) – </p></li>
<li><p><strong>scalar_B</strong> (<em>bool</em>) – </p></li>
<li><p><strong>diagonal_R</strong> (<em>bool</em>) – </p></li>
<li><p><strong>mean_type</strong> (<em>Mean</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.B_tilde">
<span class="sig-name descname"><span class="pre">B_tilde</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.B_tilde" title="Link to this definition">¶</a></dt>
<dd><p>Outputs the discarded noise factor B_tilde from the reference paper.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:returns: Discarded noise factor B_tilde (see reference paper), symmetric or even diagonal matrix of size (n_tasks - n_latents).</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_likelihood=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_lmc_coeffs=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">BDN=True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diagonal_B=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scalar_B=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diagonal_R=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_type=&lt;class</span> <span class="pre">'gpytorch.means.constant_mean.ConstantMean'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.__init__" title="Link to this definition">¶</a></dt>
<dd><p>Initialization of the model. Note that the optional arguments of the ExactGPModel also apply here thanks to the inheritance.
:type train_x: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param train_x: training input data
:type train_y: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param train_y: training input labels
:type n_tasks: <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>
:param n_tasks: number of output tasks
:type n_latents: <code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>
:param n_latents: number of latent processes
:type proj_likelihood: <code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>]
:param proj_likelihood: batched independant likelihood of size n_latents for latent processes. Defaults to None.
:type init_lmc_coeffs: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param init_lmc_coeffs: whether to initialize LMC coefficients with SVD of the training labels. Defaults to False.
:type BDN: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param BDN: whether to enforce the Block Diagonal Noise approximation (see reference article), making for a block-diagonal task noise matrix. Defaults to True.
:type diagonal_B: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param diagonal_B: whether to parametrize a diagonal noise factor B_tilde (see reference article), a simplification which theoretically causes no loss of generality. Defaults to False.
:type scalar_B: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param scalar_B: whether to parametrize a scalar noise factor B_tilde (see reference article). Defaults to False.
:type diagonal_R: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param diagonal_R: whether to parametrize a diagonal scale component for the mixing matrix (see reference article). Defaults to False.
:type mean_type: <code class="xref py py-class docutils literal notranslate"><span class="pre">Mean</span></code>
:param mean_type: gpytorch mean function for task-level processes. Defaults to gpytorch.means.ConstantMean.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>train_y</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>n_tasks</strong> (<em>int</em>) – </p></li>
<li><p><strong>n_latents</strong> (<em>int</em>) – </p></li>
<li><p><strong>proj_likelihood</strong> (<em>None</em><em> | </em><em>Likelihood</em>) – </p></li>
<li><p><strong>init_lmc_coeffs</strong> (<em>bool</em>) – </p></li>
<li><p><strong>BDN</strong> (<em>bool</em>) – </p></li>
<li><p><strong>diagonal_B</strong> (<em>bool</em>) – </p></li>
<li><p><strong>scalar_B</strong> (<em>bool</em>) – </p></li>
<li><p><strong>diagonal_R</strong> (<em>bool</em>) – </p></li>
<li><p><strong>mean_type</strong> (<em>Mean</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.compute_latent_distrib">
<span class="sig-name descname"><span class="pre">compute_latent_distrib</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.compute_latent_distrib" title="Link to this definition">¶</a></dt>
<dd><p>Outputs (distributional) posterior values of the latent processes at the input locations. This is the function which is called to compute
the loss during training.
:type x: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param x: input data tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormal</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A batched gpytorch multivariate normal distribution representing latent processes values, which mean has shape n_latents x n_points.</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.
:type x: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param x: Data to evaluate the model at</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">MultivariateNormal</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Prior distribution of the model output at the input locations. Can be a multitask multivariate normal if batch dimension is &gt;1, or a multivariate normal otherwise</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.full_likelihood">
<span class="sig-name descname"><span class="pre">full_likelihood</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.full_likelihood" title="Link to this definition">¶</a></dt>
<dd><p>Returns the full cross-tasks likelihood of the model.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">MultitaskGaussianLikelihood</span></code>
:returns: A multitask gaussian likelihood (gpytorch object) with covariance matrix Sigma (see reference article)</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>MultitaskGaussianLikelihood</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.project_data">
<span class="sig-name descname"><span class="pre">project_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.project_data" title="Link to this definition">¶</a></dt>
<dd><p>Takes some data Z as input and returns its “projected” counterpart ZT.
:type data: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param data: some array of shape … x n_tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The array ZT, where Z is the input and T the projection matrix from the reference article.</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.projected_noise">
<span class="sig-name descname"><span class="pre">projected_noise</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.projected_noise" title="Link to this definition">¶</a></dt>
<dd><p>Returns a vector of size n_latents containing the modeled noises of latent processes. Its diagonal embedding is the matrix Sigma_P from the article.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedGPModel.projection_matrix">
<span class="sig-name descname"><span class="pre">projection_matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedGPModel.projection_matrix" title="Link to this definition">¶</a></dt>
<dd><p>Returns matrix T from the article of shape n_tasks x n_latents, such that YT is the “projected data” seen by latent processes</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.ProjectedLMCmll">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">ProjectedLMCmll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedLMCmll" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ExactMarginalLogLikelihood</span></code></p>
<p>The loss function for the ProjectedGPModel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_likelihood</strong> (<em>Likelihood</em>) – </p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="#projected_lmc.ProjectedGPModel" title="projected_lmc.ProjectedGPModel"><em>ProjectedGPModel</em></a>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedLMCmll.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_likelihood</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedLMCmll.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_likelihood</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Likelihood</span></code>) – the likelihood of a ProjectedGPModel (batched gaussian likelihood of size n_latents)</p></li>
<li><p><strong>model</strong> (<a class="reference internal" href="#projected_lmc.ProjectedGPModel" title="projected_lmc.ProjectedGPModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">ProjectedGPModel</span></code></a>) – any ProjectedGPModel.</p></li>
</ul>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>RuntimeError</strong> – rejects non-gaussian likelihoods.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ProjectedLMCmll.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">latent_function_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">params</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ProjectedLMCmll.forward" title="Link to this definition">¶</a></dt>
<dd><p>Computes the value of the loss (MLL) given the model predictions and the observed values at training locations.
:type latent_function_dist: <code class="xref py py-class docutils literal notranslate"><span class="pre">Distribution</span></code>
:param latent_function_dist: gpytorch batched gaussian distribution of size n_latents x n_points representing the values of latent processes.
:type target: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>
:param target: training labels Y of shape n_points x n_tasks</p>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>RuntimeError</strong> – rejects non-gaussian latent distributions.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The (scalar) value of the MLL loss for this model and data.</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>latent_function_dist</strong> (<em>Distribution</em>) – </p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – </p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.ScalarParam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">ScalarParam</span></span><a class="headerlink" href="#projected_lmc.ScalarParam" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Torch parametrization for a scalar matrix.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ScalarParam.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ScalarParam.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.ScalarParam.right_inverse">
<span class="sig-name descname"><span class="pre">right_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.ScalarParam.right_inverse" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>A</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.TriangularParam">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">TriangularParam</span></span><a class="headerlink" href="#projected_lmc.TriangularParam" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Torch parametrization for an upper triangular matrix.</p>
<dl class="field-list simple">
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.TriangularParam.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.TriangularParam.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>X</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.TriangularParam.right_inverse">
<span class="sig-name descname"><span class="pre">right_inverse</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">A</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.TriangularParam.right_inverse" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Parameters<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>A</strong> (<em>Tensor</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="projected_lmc.VariationalMultitaskGPModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">VariationalMultitaskGPModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_ind_ratio=1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_lmc_coeffs=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_scales=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_width=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_type=&lt;class</span> <span class="pre">'gpytorch.means.constant_mean.ConstantMean'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'gpytorch.kernels.rbf_kernel.RBFKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomp=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distrib=&lt;class</span> <span class="pre">'gpytorch.variational.cholesky_variational_distribution.CholeskyVariationalDistribution'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_strat=&lt;class</span> <span class="pre">'gpytorch.variational.variational_strategy.VariationalStrategy'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ker_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.VariationalMultitaskGPModel" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ApproximateGP</span></code></p>
<p>A standard variational LMC model using gpytorch functionalities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>n_latents</strong> (<em>int</em>) – </p></li>
<li><p><strong>n_tasks</strong> (<em>int</em>) – </p></li>
<li><p><strong>train_ind_ratio</strong> (<em>float</em>) – </p></li>
<li><p><strong>seed</strong> (<em>int</em>) – </p></li>
<li><p><strong>init_lmc_coeffs</strong> (<em>bool</em>) – </p></li>
<li><p><strong>train_y</strong> (<em>Tensor</em><em> | </em><em>None</em>) – </p></li>
<li><p><strong>prior_scales</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>prior_width</strong> (<em>Tensor</em>) – </p></li>
<li><p><strong>mean_type</strong> (<em>Mean</em>) – </p></li>
<li><p><strong>kernel_type</strong> (<em>Kernel</em>) – </p></li>
<li><p><strong>decomp</strong> (<em>list</em><em>[</em><em>list</em><em>[</em><em>int</em><em>]</em><em>] </em><em>| </em><em>None</em>) – </p></li>
<li><p><strong>distrib</strong> (<em>_VariationalDistribution</em>) – </p></li>
<li><p><strong>var_strat</strong> (<em>_VariationalStrategy</em>) – </p></li>
<li><p><strong>ker_kwargs</strong> (<em>dict</em><em> | </em><em>None</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.VariationalMultitaskGPModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_latents</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_tasks</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_ind_ratio=1.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed=0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init_lmc_coeffs=False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_y=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_scales=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_width=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mean_type=&lt;class</span> <span class="pre">'gpytorch.means.constant_mean.ConstantMean'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_type=&lt;class</span> <span class="pre">'gpytorch.kernels.rbf_kernel.RBFKernel'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomp=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distrib=&lt;class</span> <span class="pre">'gpytorch.variational.cholesky_variational_distribution.CholeskyVariationalDistribution'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">var_strat=&lt;class</span> <span class="pre">'gpytorch.variational.variational_strategy.VariationalStrategy'&gt;</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ker_kwargs=None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">**kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.VariationalMultitaskGPModel.__init__" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_x</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>) – training input data</p></li>
<li><p><strong>n_latents</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of latent processes</p></li>
<li><p><strong>n_tasks</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – number of output tasks</p></li>
<li><p><strong>train_ind_ratio</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">float</span></code>) – ratio between the number of training points and this of inducing points. Defaults to 1.5.</p></li>
<li><p><strong>seed</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – Random seed for inducing points generation. Defaults to 0.</p></li>
<li><p><strong>init_lmc_coeffs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to initialize LMC coefficients with the SVD of the training labels. Defaults to False.</p></li>
<li><p><strong>train_y</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – training data labels, used only for the SVD initialization of LMC coefficients. Defaults to None.</p></li>
<li><p><strong>prior_scales</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Prior mean for characteristic lengthscales of the kernel. Defaults to None.</p></li>
<li><p><strong>prior_width</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – Prior deviation-to-mean ratio for characteristic lengthscales of the kernel. Defaults to None.</p></li>
<li><p><strong>mean_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Mean</span></code>) – gpytorch mean function for the outputs. Defaults to gpytorch.means.ConstantMean.</p></li>
<li><p><strong>kernel_type</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code>) – . gpytorch kernel function for latent processes. Defaults to gpytorch.kernels.RBFKernel.</p></li>
<li><p><strong>decomp</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – instructions to create a composite kernel with subgroups of variables. Ex : decomp = [[0,1],[1,2]] –&gt; k(x0,x1,x2) = k1(x0,x1) + k2(x1,x2). Defaults to None.</p></li>
<li><p><strong>distrib</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_VariationalDistribution</span></code>) – gpytorch variational distribution for inducing values (see gpytorch documentation). Defaults to gpytorch.variational.CholeskyVariationalDistribution.</p></li>
<li><p><strong>var_strat</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">_VariationalStrategy</span></code>) – gpytorch variational strategy (see gpytorch documentation). Defaults to gpytorch.variational.VariationalStrategy.</p></li>
<li><p><strong>ker_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>]) – Additional arguments to pass to the gpytorch kernel function. Defaults to None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.VariationalMultitaskGPModel.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.VariationalMultitaskGPModel.forward" title="Link to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.
:rtype: <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>Tensor</em>) – </p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><em>Tensor</em></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.VariationalMultitaskGPModel.lmc_coefficients">
<span class="sig-name descname"><span class="pre">lmc_coefficients</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.VariationalMultitaskGPModel.lmc_coefficients" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.VariationalMultitaskGPModel.lscales">
<span class="sig-name descname"><span class="pre">lscales</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unpacked</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.VariationalMultitaskGPModel.lscales" title="Link to this definition">¶</a></dt>
<dd><p>Displays the learned characteric lengthscales of the kernel(s).
:type unpacked: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param unpacked: whether to unpack the output list and trim useless dimensions of the tensor. Applies only if the model kernel is not composite</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>], <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of tensors representing the learned characteristic lengthscales of each subkernel and each task (or a single tensor if the kernel is non-composite and unpacked=True).
Each one has shape n_latents x n_dims (n_dim number of dimensions of the subkernel)</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>unpacked</strong> (<em>bool</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="projected_lmc.VariationalMultitaskGPModel.outputscale">
<span class="sig-name descname"><span class="pre">outputscale</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">unpacked</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.VariationalMultitaskGPModel.outputscale" title="Link to this definition">¶</a></dt>
<dd><p>Displays the outputscale(s) of the kernel(s).
:type unpacked: <code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>
:param unpacked: whether to trim useless dimensions of the tensor</p>
<dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensors representing the learned outputscales of each subkernel and each task (shape n_latents x n_kernels)</p>
</dd>
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>unpacked</strong> (<em>bool</em>) – </p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="projected_lmc.handle_covar_">
<span class="sig-prename descclassname"><span class="pre">projected_lmc.</span></span><span class="sig-name descname"><span class="pre">handle_covar_</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">kernel</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decomp</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_funcs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_scales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prior_width</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputscales</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ker_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#projected_lmc.handle_covar_" title="Link to this definition">¶</a></dt>
<dd><p>An utilitary to create and initialize covariance functions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code>) – basis kernel type</p></li>
<li><p><strong>dim</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – dimension of the data (number of variables)</p></li>
<li><p><strong>decomp</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>]]]) – instructions to create a composite kernel with subgroups of variables. Defaults to None</p></li>
<li><p><strong>Ex</strong> – decomp = [[0,1],[1,2]] –&gt; k(x0,x1,x2) = k1(x0,x1) + k2(x1,x2)</p></li>
<li><p><strong>n_funcs</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">int</span></code>) – batch dimension (number of tasks or latent functions depending on the case), defaults to 1</p></li>
<li><p><strong>prior_scales</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – mean values of the prior for characteristic lengthscales. Defaults to None</p></li>
<li><p><strong>prior_width</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]) – deviation_to_mean ratio of the prior for characteristic lengthscales. Defaults to None</p></li>
<li><p><strong>outputscales</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">bool</span></code>) – whether or not the full kernel has a learned scaling factor, i.e k(x) = a* k’(x).</p></li>
<li><p><strong>nontrivial</strong> (<em>If decomp is</em>) – </p></li>
<li><p><strong>True</strong> (<em>each subkernel is automatically granted an outputscale. Defaults to</em>) – </p></li>
<li><p><strong>ker_kwargs</strong> (<code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code>]) – additional arguments to pass to the underlying gpytorch kernel. Defaults to None</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">Kernel</span></code></p>
</dd>
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A gpytorch-compatible kernel</p>
</dd>
</dl>
</dd></dl>

</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">projected_lmc module</a><ul>
<li><a class="reference internal" href="#projected_lmc.CustomLMCVariationalStrategy"><code class="docutils literal notranslate"><span class="pre">CustomLMCVariationalStrategy</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.CustomLMCVariationalStrategy.__init__"><code class="docutils literal notranslate"><span class="pre">CustomLMCVariationalStrategy.__init__()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.ExactGPModel"><code class="docutils literal notranslate"><span class="pre">ExactGPModel</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.ExactGPModel.__init__"><code class="docutils literal notranslate"><span class="pre">ExactGPModel.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ExactGPModel.forward"><code class="docutils literal notranslate"><span class="pre">ExactGPModel.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ExactGPModel.lscales"><code class="docutils literal notranslate"><span class="pre">ExactGPModel.lscales()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ExactGPModel.outputscale"><code class="docutils literal notranslate"><span class="pre">ExactGPModel.outputscale()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.LMCMixingMatrix"><code class="docutils literal notranslate"><span class="pre">LMCMixingMatrix</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.LMCMixingMatrix.Q"><code class="docutils literal notranslate"><span class="pre">LMCMixingMatrix.Q()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.LMCMixingMatrix.Q_orth"><code class="docutils literal notranslate"><span class="pre">LMCMixingMatrix.Q_orth()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.LMCMixingMatrix.__init__"><code class="docutils literal notranslate"><span class="pre">LMCMixingMatrix.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.LMCMixingMatrix.forward"><code class="docutils literal notranslate"><span class="pre">LMCMixingMatrix.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.LMCMixingMatrix.size"><code class="docutils literal notranslate"><span class="pre">LMCMixingMatrix.size()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.MultitaskGPModel"><code class="docutils literal notranslate"><span class="pre">MultitaskGPModel</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.MultitaskGPModel.__init__"><code class="docutils literal notranslate"><span class="pre">MultitaskGPModel.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.MultitaskGPModel.forward"><code class="docutils literal notranslate"><span class="pre">MultitaskGPModel.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.MultitaskGPModel.lmc_coefficients"><code class="docutils literal notranslate"><span class="pre">MultitaskGPModel.lmc_coefficients()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.MultitaskGPModel.lscales"><code class="docutils literal notranslate"><span class="pre">MultitaskGPModel.lscales()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.MultitaskGPModel.outputscale"><code class="docutils literal notranslate"><span class="pre">MultitaskGPModel.outputscale()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.PolynomialMean"><code class="docutils literal notranslate"><span class="pre">PolynomialMean</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.PolynomialMean.__init__"><code class="docutils literal notranslate"><span class="pre">PolynomialMean.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.PolynomialMean.forward"><code class="docutils literal notranslate"><span class="pre">PolynomialMean.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.PositiveDiagonalParam"><code class="docutils literal notranslate"><span class="pre">PositiveDiagonalParam</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.PositiveDiagonalParam.forward"><code class="docutils literal notranslate"><span class="pre">PositiveDiagonalParam.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.PositiveDiagonalParam.right_inverse"><code class="docutils literal notranslate"><span class="pre">PositiveDiagonalParam.right_inverse()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.PositiveTriangularParam"><code class="docutils literal notranslate"><span class="pre">PositiveTriangularParam</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.PositiveTriangularParam.forward"><code class="docutils literal notranslate"><span class="pre">PositiveTriangularParam.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.B_tilde"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.B_tilde()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.__init__"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.compute_latent_distrib"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.compute_latent_distrib()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.forward"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.full_likelihood"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.full_likelihood()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.project_data"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.project_data()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.projected_noise"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.projected_noise()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedGPModel.projection_matrix"><code class="docutils literal notranslate"><span class="pre">ProjectedGPModel.projection_matrix()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.ProjectedLMCmll"><code class="docutils literal notranslate"><span class="pre">ProjectedLMCmll</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.ProjectedLMCmll.__init__"><code class="docutils literal notranslate"><span class="pre">ProjectedLMCmll.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ProjectedLMCmll.forward"><code class="docutils literal notranslate"><span class="pre">ProjectedLMCmll.forward()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.ScalarParam"><code class="docutils literal notranslate"><span class="pre">ScalarParam</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.ScalarParam.forward"><code class="docutils literal notranslate"><span class="pre">ScalarParam.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.ScalarParam.right_inverse"><code class="docutils literal notranslate"><span class="pre">ScalarParam.right_inverse()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.TriangularParam"><code class="docutils literal notranslate"><span class="pre">TriangularParam</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.TriangularParam.forward"><code class="docutils literal notranslate"><span class="pre">TriangularParam.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.TriangularParam.right_inverse"><code class="docutils literal notranslate"><span class="pre">TriangularParam.right_inverse()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.VariationalMultitaskGPModel"><code class="docutils literal notranslate"><span class="pre">VariationalMultitaskGPModel</span></code></a><ul>
<li><a class="reference internal" href="#projected_lmc.VariationalMultitaskGPModel.__init__"><code class="docutils literal notranslate"><span class="pre">VariationalMultitaskGPModel.__init__()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.VariationalMultitaskGPModel.forward"><code class="docutils literal notranslate"><span class="pre">VariationalMultitaskGPModel.forward()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.VariationalMultitaskGPModel.lmc_coefficients"><code class="docutils literal notranslate"><span class="pre">VariationalMultitaskGPModel.lmc_coefficients()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.VariationalMultitaskGPModel.lscales"><code class="docutils literal notranslate"><span class="pre">VariationalMultitaskGPModel.lscales()</span></code></a></li>
<li><a class="reference internal" href="#projected_lmc.VariationalMultitaskGPModel.outputscale"><code class="docutils literal notranslate"><span class="pre">VariationalMultitaskGPModel.outputscale()</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#projected_lmc.handle_covar_"><code class="docutils literal notranslate"><span class="pre">handle_covar_()</span></code></a></li>
</ul>
</li>
</ul>

  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/projected_lmc.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">projected-lmc 0.0.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">projected_lmc module</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2023, QWERTY6191.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    </div>
  </body>
</html>